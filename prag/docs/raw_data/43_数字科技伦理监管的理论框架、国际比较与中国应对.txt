# -*- coding: utf-8 -*-

## 政策标题：
数字科技伦理监管的理论框架、国际比较与中国应对

## 政策来源：
中国社会科学院工业经济研究所

## 政策内容：
摘要：在数字科技主导的新一轮技术革命加速演化进程中产生了诸多道德伦理冲突与社会问题，构建一套契合数字科技发展规律的数字科技伦理监管体系尤为必要。在构建数字科技伦理监管的“有效市场—有为政府—有力社会”的监管框架下，本文着重梳理分析全球主要发达国家数字科技伦理监管的主要主体、重点议题与政策布局、监管模式等，在主要主体方面涵盖政府、行业协会与社会组织、企业等多重主体；在重点议题与政策布局方面涵盖人工智能伦理、大数据伦理、区块链伦理等方面；在监管模式方面涵盖立法主导式、“整体政府”统筹式、“泛国家”统筹式、政府部门与跨政府组织联动式、多元社会主体分散参与式等多重差异性监管模式与机制。本文认为中国应加快构建契合中国国情的数字科技伦理监管体系，在监管制度设计方面重视政府立法的前瞻性引导作用，充分发挥地方政府监管的自主性与积极性，在监管模式设计方面需要形成政府、企业与社会多元主体共同参与的监管模式，在监管合作层面需要加快形成面向国际社会广泛合作交流的数字科技伦理监管体系。

关键词：数字科技伦理；监管体系；发达国家；经验借鉴

基金：国家社会科学基金重大项目“国企混合所有制改革的实现路径选择研究”（20&ZD073）；中国社会科学院国情调研重大项目“数字科技伦理监管制度调查研究”（GQZD2023009）；中国社会科学院登峰战略企业管理优势学科建设项目。

 

一、引言

新一轮技术革命本质上是以人工智能、大数据、区块链和虚拟现实等数字科技主导的技术革命。相比于前几轮技术革命，新一轮技术革命下的技术创新效应与产业变革效应的联系更为紧密，呈现出技术革命与产业变革的交替共演趋势。在数字智能技术迅猛发展下，直接催生出了全新的数字经济形态，数字经济下的数字化产业与产业数字化成为主要的产业基础。近年来，世界各国加快了面向数字科技、数字经济与数字产业的宏观战略布局与政策部署，特别是发达国家的数字科技总体上呈现出多点开花的蓬勃发展态势，在人工智能技术、区块链技术、大数据技术、移动互联网技术等方面迅猛发展。其中，美国在数字科技竞争方面长期居于世界领导地位，其重点关注人工智能领域。美国人工智能技术的应用领域主要是军事领域和民用商业领域。在数字科技产业化与商业化应用领域，美国同样培育了一大批全球人工智能科技领军企业。值得关注的是，2022年11月，微软公司旗下的开放人工智能研究中心（OpenAI）发布了全新的聊天生成预训练转换器（ChatGPT），这意味着在人工智能领域新的生成式人工智能（AI）的革命由此开始，也进一步标志着人工智能在自然语言处理领域进入了全新时代。相比于美国人工智能技术在数字科技领域中的领导地位，欧盟则更加重视大数据技术特别是开放数据体系建设，并且注重互联网移动通信技术的大规模普及与应用，在5G通信技术领域欧盟成为全球的积极推动者和部分应用领域的引领者。2020年2月，欧盟委员会发布的《欧洲数据战略》中明确提出欧盟要成为世界上最具吸引力、最安全和最具活力的数据敏捷型经济体的新愿景。在5G通信技术领域，欧盟针对5G通信技术制定了明确的发展计划，以期引领全球移动通信新标准。《2022年欧洲移动经济报告》显示，预计到2025年，欧洲5G通信技术的平均普及率可达到44%。其中，欧盟成员国德国的5G通信技术普及率在欧洲最高，将达到59%。可以看到，全球主要发达国家或地区都不同程度地围绕数字科技与数字经济开展系列政策部署与战略布局，意图在全球新一轮数字技术革命中获得优势地位。

近年来，中国对数字经济发展高度重视，党的二十大报告明确提出：“加快发展数字经济，促进数字经济和实体经济深度融合，打造具有国际竞争力的数字产业集群。”2022年，国务院发布《“十四五”数字经济发展规划》《国务院关于加强数字政府建设的指导意见》，各地方政府对数字经济发展规划相继出台，整体上呈现出“中央—地方”对数字经济发展的产业政策、财税政策和金融政策的联动协同局面。根据2023年中国信息通信研究院发布的《中国数字经济发展研究报告（2023年）》，2022年中国数字经济规模达到50.2万亿元，同比名义增长10.3%，已连续11年超过同期GDP名义增速，数字经济占GDP的比重高达41.5%，足以说明数字经济已经成为国民经济的主导力量。不容忽视的现实是，尽管数字经济、数字产业和数字企业推动中国国民经济与社会发展的良好态势不断强化与深化，但数字科技作为数字经济形态演化与数字产业发展的底层技术，其在创新与应用发展过程中出现了大量的负面社会问题，数字科技的负外部性成为各国政府开展数字科技伦理监管的主要方向，也成为数字经济宏观监管与数字企业微观治理的重点领域。从现有研究来看，关于数字科技伦理监管的研究呈现出四大主线：第一条主线针对数字科技伦理监管的概念内涵开展研究，如李正风和王硕[1]认为，数字科技伦理涵盖个体、企业、社会和人类等层面。第二大主线针对数字科技的重点领域开展研究，特别是针对数字科技伦理监管的重点内容和主导模式设计研究，包括对算法伦理[2]、人工智能伦理[3，4]、大数据伦理[5，6]、区块链伦理[7]等不同领域的数字科技伦理监管开展差异化的监管内容与实现机制探索。第三条主线针对数字科技创新与应用的主要微观主体开展研究，包括数字平台企业监管与社会责任治理范式重塑[8，9，10]。第四条主线针对具体国家的数字科技伦理监管政策布局与制度设计开展研究，包括数字科技伦理监管的主要趋势与监管模式[11]。

总体而言，学术界针对数字科技伦理监管的研究处于起步阶段，尚未形成关于数字科技伦理监管的整体性研究框架，对于数字科技伦理监管的必要性、合理性和价值性等问题缺乏深入回答，数字科技伦理监管的一般性理论框架尚未明晰，且面向全球范围内的数字科技伦理监管的趋势与共性规律尚不明确。基于此，本文尝试搭建数字科技伦理监管的一般性理论框架，从全球主要发达国家的视角系统梳理与总结面向数字科技伦理监管的主要政策布局与监管内容，提炼全球数字科技伦理监管的一般规律与主要趋势，最终面向中国数字科技伦理监管体系提出针对性经验借鉴。

二、数字科技伦理监管：一个理论框架

（一）数字科技伦理监管的主要内涵

准确理解数字科技伦理需要回归技术伦理的一般性理论内涵。技术是人类社会实践的产出，表现为科学工作者、从事工程技术研究与开发的相关主体（个体与组织等）在技术开发、应用与创新扩散过程等不同阶段中开展的系列科学与创新实践。技术伦理包括在技术形成、技术开发和技术应用过程中对技术涉及到的人类价值规范、道德伦理和社会规范等方面的系列议题，其内在原因在于人具有道德性与社会性，组织也不例外，技术作为人与组织在社会实践中的产出，其必然需要契合人类的价值尺度，技术活动本身并不是孤立存在[12]，而是存在于社会关系范畴之中，相应地，技术的形成与创新发展离不开道德伦理和社会规范的干预调节，形成技术与人、技术与社会、技术与人类文明的多重共生[11，13]。技术伦理研究主要包括三个研究层次：第一，技术涉及的科学工作者、工程技术人员的专业道德伦理问题，表现为个体层面的道德伦理实践，探索个体如何能够恪守职业道德、确保在个体从事科学研究与技术活动的系列行为符合道德伦理、社会规范，承担道德责任与伦理责任。第二，技术形成和技术应用过程中涉及的主要组织，包括市场组织、政府部门和社会组织等多元主体在技术开发与创新应用中的系列道德伦理问题，这意味着从关注个体的伦理道德转向关注具有集体意义上的组织道德，将科学技术运行过程置于特定的组织运行过程之中，考察组织在技术形成、技术开发和技术应用过程中的系列伦理道德议题，确保组织的道德性，在满足组织主要价值创造目标的过程中不产生道德伦理冲突以及系列负面社会问题。第三，技术整体的创新发展与人类社会价值、传统道德伦理之间的关系，以及相互调适的普遍规律。这意味着技术伦理研究范畴从个体与组织转向了更高层次范畴的技术演化进程视角，从科学技术整体的发展演化视角考察现有道德伦理标准的适用性及其相互调适与共演规律，从这个意义上，伦理道德不仅仅能够调节技术形成与应用的各个阶段，而且技术整体发展也能够产生价值规范与道德伦理的整体性变迁，二者呈现出相互调适的状态。特别是对于新兴技术而言，新兴技术发展进程中呈现出较大的不确定性，新兴技术由于自身性质模糊、未来应用场景不明确、潜在的演化路线高度不确定性等诸多原因，新兴技术创新发展过程中往往会逐步调整甚至改变部分传统伦理道德观念，在技术创新与应用过程中逐步探索技术与伦理道德之间的共生与契合问题。

随着技术革命不断演进，数字科技作为一种全新的技术力量在重塑宏观经济形态与微观生产方式的同时，也悄然改变着社会运行方式，数字社会成为数字科技时代下的全新社会形态。不同于前两次能源技术主导的“硬科技”革命，数字科技主导的新一轮技术革命对社会的渗透与赋能效应更为显著，这意味着数字科技塑造数字社会的同时也对传统道德伦理规范产生全新的冲击。基于技术伦理的视角，数字科技伦理是在数字科技形成与创新应用过程应该遵循的一整套行为道德准则与价值观念，涵盖数字技术开发、数字技术利用、数字科技术创新过程中相关主体（个体、组织与集体）的道德范畴、伦理准则与行为规范。而数字科技伦理监管则是从监管主体与功能的视角出发，构建一套契合数字科技这一全新技术经济范式的监管体系与监管模式，确保数字科技在形成、应用与创新发展过程中契合人的价值、社会价值与自然价值，确保数字科技能够与人共生、与社会共生、与自然共生，确保数字科技主导的新一轮技术革命能够对整个经济与社会环境创造可持续的正外部性。

（二）数字科技伦理监管：“政府—企业—社会”的三维分析框架

监管是一种具有公共意志的公共行为，这意味着开展监管活动的监管主体一定程度上需要具备一定的公共社会属性，才能通过资源配置活动实现社会福利最优和公共利益最大化。数字科技伦理监管是公共规制主体规范从事数字科技开发、应用和创新的相关组织和主体的伦理行为的系列制度安排和政策体系，在监管过程中充分调动市场主体、多元社会主体的积极性和能动性，最大程度地实现监管目标合意、监管过程合法、监管手段合理和监管价值合效。对于政府与市场之间的关系，自古典经济学提出以来便开展广泛地讨论，亚当·斯密认为市场作为“看不见的手”通过价格、供求和竞争等实现市场行为的自发调节与资源充分配置，但在公共领域（如公共产品供给方面）市场主体的“市场逻辑”至上，难以对无利可图的公共领域开展资源配置，这时需要政府这一公共规制主体承担资源配置角色，充分弥补市场失灵，进而形成“看不见的手”和“看得见的手”充分实现资源配置。这意味着市场在资源配置中起主导作用，政府仅仅在部分市场失灵领域承担弥补市场失灵的相关作用。而新古典经济学秉承市场万能论，基于“经济人”这一基本假设，在充分竞争的市场环境下市场能够自动出清，这意味着市场成为资源配置的唯一手段，对于数字科技伦理监管体系构建而言，在古典经济学与新古典经济学视角下，监管的重点在于充分发挥市场的作用，即市场中的微观企业能够自发地构建契合数字科技开发、应用与创新扩散过程中的道德伦理规范，通过构建企业自我为中心的伦理监管与治理体系，实现数字科技伦理监管的有效性。因此，在市场主导的数字科技伦理监管体系下，企业成为开展数字科技伦理监管的中心，即企业需要具备高度的道德自觉和伦理自省，在数字技术开发、应用和创新过程中充分考虑伦理道德与社会规范，进而实现数字科技伦理监管的企业自我监管。然而事实上，社会道德与伦理场域之中往往“无利可图”，甚至当伦理道德与社会规范对从事数字科技开发、应用与创新扩散的相关主体产生潜在的冲突时，此时以企业为中心的数字科技伦理自我监管将立即失效。

公共监管论突破了古典经济学与新古典经济学的束缚，认为市场主体具有自发性，依靠市场主体企业实现资源配置存在诸多市场失灵问题，政府作为公共监管主体的功能不限定于提供公共产品和公共服务，也包括在广泛的市场领域内纠正市场失灵与提高资源配置效率，此时政府与市场表现为“强政府—强市场”下的交互关系。就数字科技伦理监管而言，公共监管下政府成为开展数字科技伦理监管的核心主体，其监管手段和方式主要是借助公共力量，通过系列公共制度安排、行政指令和具体规则等对市场主体的相关行为开展直接性的干预或引导调适，特别是对相关市场的准入规则、价格管制和监管反馈等形成“事前—事中—事后”的监管体系。此时，强政府监管下的数字科技伦理监管表现为数字市场的准入规则、数字技术创新的制度规范、数字企业的相关技术开发、应用和创新行为指引等成为政府监管的常规手段。更为重要的是，公共监管论下政府能够通过信号效应合理引导市场主体的市场预期，在数字科技伦理监管过程中表现为对数字科技创新的市场预期的合理调适，确保企业在数字科技开发、应用和创新过程中创造的个体经济价值不破坏社会福利，通过政府的协调能力和纠错机制最大程度包容创新并降低潜在的社会风险。

“强政府—强市场”下的数字科技伦理监管体系并不意味着数字科技伦理监管各个监管领域能够充分有效，原因在于公共监管论虽然一定程度上弥补了市场万能主义或政府公共物品论的若干缺陷，但政府作为公共规制主体，依然存在广泛的政府公共失灵现象，具体表现为政府权力寻租、利益集团规制俘获、资源配置腐败和注意力选择性失灵等。此时，作为超越“强政府—强市场”的第三重进路，积极有为的社会公共力量发挥重要作用。特别是对于数字技术这一高度具有社会赋能效应和社会扩散效应的技术体系而言，其在形成、应用和创新过程中离不开社会公众特别是广大用户的积极参与。在高度不确定性与应用场景不清晰的数字技术创新过程中，发挥行业协会、技术专家和社会公众等社会力量便十分关键。调动数字科技相关研发人员的责任式创新理念、责任型数字企业以及社会公众监督与治理等多重合力，实现对“强政府—强市场”下若干失灵领域的有效补充，最终构建一套“有效市场—有为政府—有力社会”下的数字科技伦理监管体系。

三、发达国家数字科技伦理监管的总体概况

（一）发达国家数字科技伦理监管的主要主体

1.政府

政府在数字科技伦理监管中发挥主导作用，但不同发达国家其政府开展数字科技伦理监管的角色和功能具有较大的差异性。

具体来看，美国开展数字科技伦理监管的政府主体包括联邦政府、国会和州政府，且分别在数字科技伦理监管中发挥不同的角色和功能。美国联邦政府是美国数字科技伦理监管的主要主体，其主要采取前瞻性立法、战略倡议的方式对数字科技伦理开展规范与引导。立法行动定义联邦人工智能政策。目前，美国联邦政府整体人工智能政策由多个机构和独立组织代表整个联邦政府开发人工智能技术或政策，分别是美国白宫科技政策办公室（OSTP）、美国总务管理局（GSA）、美国国家人工智能安全委员会（NSCAI）、美国白宫管理和预算办公室（OMB）、美国商务部（DOC）、美国国土安全部科学技术局（S&T）。与此同时，美国州政府发挥地方性立法的重要作用，且相当程度上美国州政府对数字科技伦理监管具有较大程度的自主权与政策制定空间。在数字科技伦理监管的重点领域，美国州政府在人工智能治理方面都有自己的举措，在提出和通过监管方面比美国联邦政府更积极更主动。在特朗普政府时期，美国联邦政府与国会通过的《2020年国家人工智能倡议法案》（National Artificial Intelligence Initiative Act of 2020，简称NAIIA）对人工智能监管采取宽松策略，州政府层面的其他立法建议则采取更主动的人工智能监管策略。例如，加利福尼亚州的《2020年自动决策系统问责法》则早于美国联邦政府。在自动驾驶汽车与人脸识别的数字科技伦理监管领域，美国州政府的监管制度与政策设计同样早于联邦政府。

欧盟数字科技伦理监管中主要的政府主体包括欧盟委员会、欧洲议会、欧洲理事会、欧洲经济和社会委员会等，以上主体在数字科技伦理监管中所发挥的作用具体如下：第一，欧盟委员会制定数字科技伦理监管政策并成立科技伦理委员会。欧盟委员会根据欧盟域内的数字科技发展情况和战略意义制定相关伦理监管政策，并将伦理监管的思想、原则和措施等内嵌到数字科技相关发展战略和资金支持计划之中。此外，科技伦理委员会对数字科技伦理监管提供指导和咨询等。欧盟出台的伦理监管政策包括《可信人工智能伦理准则》《人工智能法案》（草案）《一般数据保护条例》《数字服务法案》等，这些政策在数字科技伦理监管制度建设中发挥着重要的作用。2019年4月8日，欧盟委员会发布了《可信赖人工智能伦理准则》，其确立了人工智能发展的三项基本要素，即人工智能技术须符合法律规定、人工智能技术须满足伦理道德原则及价值、人工智能在技术和社会层面应具有可靠性，其提出了7条人工智能伦理准则。2020年2月，欧盟委员会发布了《欧洲数据战略》，其在实现建立欧盟单一数据市场的愿景基础上，提出要建立包含公共数据的使用和共享、个人数据的使用和网络安全等领域的统一数据治理框架。第二，欧洲议会和欧洲理事会制定和审议数字科技伦理监管的相关法律法规，欧洲议会在数字科技伦理监管领域所发挥的作用主要体现在针对相关数字科技制定相应的伦理监管法律，并在欧盟域内推行。早在2016年，欧洲议会法律事务委员会就针对机器人的伦理监管发布了《就机器人民事法律规则向欧盟委员会提出立法建议的报告草案》和《欧盟机器人民事法律规则》，其提出了对机器人工程师伦理准则、机器人研究伦理委员会伦理准则和使人类免受机器人伤害的基本伦理原则。欧洲议会和欧洲理事会还针对欧盟委员会提出的数字科技监管政策或法案进行审议并提出相应的修正案或建议，有助于相关监管政策的进一步完善。第三，欧盟经济和社会委员会对数字科技伦理现实情况开展调查和研究，为相关监管政策的制定提供有力支撑。

英国政府同样在数字科技伦理监管中发挥重要作用，其对人工智能伦理监管、大数据伦理监管和区块链伦理监管等方面采取差异性的监管功能定位。在人工智能伦理监管方面，主要政府部门包括英国数字、文化、媒体和体育部（DCMS）、英国商业、能源和工业战略部（BEIS）、英国内政部（Home Office）。在大数据伦理监管方面，主要政府部门包括内阁办公厅（Cabinet Office）、英国国家统计局（ONS）、英国卫生和社会保健部（DHSC）、英国外交、联邦和发展事务部（FCDO）、苏格兰政府（分权行政机构）、威尔士政府（分权行政机构）。在区块链伦理监管方面，主要政府部门包括英国财政部、金融行为监管局（FCA）。

日本政府在数字科技伦理监管中也发挥了重要作用，主要的政府主体包括日本内阁府、日本总务省、经济产业省、数字厅、厚生劳动省等，分别在监管原则、规则制定、监管过程监督和执法等方面发挥重要作用。日本把原则作为数字科技伦理监管的理论依据和终极目标。2018年，日本内阁府发布了《以人为中心人工智能社会原则》，其要求在人工智能开发、利用过程中遵守7项基本原则，不得利用技术手段做出非伦理行为。这7项基本原则决定了日本人工智能伦理监管的目标、内容和价值取向，为日本人工智能伦理监管提供了依据。

2.行业协会与社会组织

行业协会与社会组织在数字科技伦理监管中发挥重要的协同和补充性功能。不同发达国家的行业协会与社会组织在参与政府主导的数字科技伦理监管中发挥不同的作用。

美国的行业协会与社会组织在数字科技伦理监管中主要扮演参与者与协同者等角色。美国开展数字科技伦理监管的行业协会包括美国商会（USCC）、美国人工智能促进协会（AAAI）等。行业协会与社会组织在欧盟数字科技伦理监管中主要为政府监管政策制定提供支持性意见、推出行业示范性规则、促进伦理监管政策实施等，其中具有代表性的行业协会与社会组织包括欧盟委员会人工智能高级专家组、欧洲人工智能联盟在线论坛和欧洲绿色数字联盟等。英国竞争和市场管理局（CMA）、英国信息专员办公室（ICO）和英国通信办公室于2020年7月组建数字监管合作论坛，旨在加强行业协会与政府之间的沟通协作以及面向在线监管领域的监管合作。韩国的行业协会与社会组织对数字科技伦理进行监管的主要有韩国人工智能协会、韩国消费者联盟、韩国人工智能法学会等。韩国人工智能协会始于2012年的创业社区活动，2017年1月7日成立为非营利法人，旨在通过构成人工智能生态系统的相关个人、企业、基础设施等的交流，完成向整个产业引进人工智能，通过人才智能化、技术智能化、产品智能化和企业智能化，追求人工智能生态系统建设战略。加拿大的行业协会与社会组织通过出台相关文件政策参与数字科技伦理监管。日本的行业协会与社会组织参与数字科技伦理监管的主体包括日本经济团体联合会、日本电子信息技术产业协会和日本云产业协会等，其在参加制定伦理规则、制定本行业伦理规则、实施伦理审查和认证、本行业伦理监督调查和参加事故调查等方面发挥重要作用。

3.企业

在政府主导、行业协会与社会组织参与的数字科技伦理监管中，市场主体也充分发挥自我监管与治理功能，表现为以企业为主体开展数字科技伦理监管。

具体来看，美国企业作为数字科技伦理监管的重要角色，承担数字科技伦理监管的参与者、互补者与协同者的重要角色。韩国企业广泛开展数字科技伦理的自我监管，包括Kakao、NAVER、CJ Olive Networks、三星电子、LG、SK、KB金融等在内的韩国代表性信息科技企业，均以不同程度、不同方式进行数字科技伦理的自我监管，各企业自2018年以来围绕“以人为本”的核心价值相继制定了与数字伦理规范相关的指导方针。例如，Kakao作为韩国信息技术领先企业首次发表了人工智能《算法伦理宪章》，NAVER适用从设计着手保护隐私（Privacy by Design）的原则，SK电信将“以人为本的AI”作为核心理念制定了“AI追求的价值”，即以“AI Company”正式进行创新，提出利用AI向顾客提供“AI追求的价值”和成员实践的标准。日本企业同样在数字科技开发、应用和创新过程中发挥重要的监管角色，表现为制定本企业伦理规则，在监督环节的自我监督、履行说明责任、内部与外部监查，在执法环节的自主改进、自主纠错、事故报告和调查配合。加拿大企业基于自身实际通过建设项目、构建标准指南等参与数字科技伦理监管。

（二）发达国家数字科技伦理监管的重点议题与政策布局

1.面向人工智能伦理监管的重点议题与政策布局

从工智能领域的数字科技伦理监管重点议题来看，全球主要发达国家都不同程度地将监管重点集中于算法伦理、人工智能安全与可信度等方面。

具体来看，近年来，美国国会通过立法的形式加快对人工智能伦理的监管与治理。2021年1月1日，美国颁布《2020年国家人工智能倡议法案》。美国对人工智能伦理监管的重点聚焦于智能算法的社会伦理影响监管，侧重于从算法研发设计到算法应用的全过程监管。2022年7月20日，美国众议院能源和商务委员会以53：2的票数通过了《美国数据隐私和保护法》（American Data Privacy and Protection Act，简称ADPPA），其提出相关实体和服务提供商必须评估算法的设计、结构和数据输入，以降低潜在歧视性影响的风险。

欧盟将维护人工智能伦理价值观上升至欧洲整体战略层面，高度重视建立人工智能伦理道德和法律框架，以确保人工智能技术朝着有益于个人和社会的方向发展。2012年开始，欧盟不断完善人工智能伦理监管政策。在人工智能伦理监管政策布局中，欧盟呈现的特点是以实际应用中出现的问题为引导，以机器人伦理监管为开端，逐渐覆盖到人工智能的研发和应用等领域，既内嵌到人工智能发展战略中，又专门制定相关的伦理监管政策或法规。欧盟还构建统一的人工智能伦理监管体系，促进监管政策的有效落地和域内的一致性。欧盟发布《人工智能时代：确立以人为本的欧洲战略》《人工智能协调计划》《人工智能白皮书：通往卓越与信任的欧洲之路》等对数字科技伦理监管采取整体性部署，同时也出台了《可信人工智能伦理准则》和《建立以人为本的可信人工智能》等多个专业性的人工智能监管准则。欧盟特别主张算法伦理监管，2019年4月，欧洲议会未来与科学和技术小组发布《算法责任与透明治理框架》，其提出对公共主体实施算法影响评估的强制要求，还将具体的算法伦理监管规则置于数据保护框架中，“数据规则+算法原则”构成了欧盟监管算法伦理的制度体系。

人工智能伦理监管成为英国政府重点监管的领域，2018年4月，英国政府发布《英国的人工智能：准备好、意愿和有能力？》，该报告基于200多位行业专家的证据，提出5项核心原则，旨在为人工智能伦理监管提供方向与指南。2019年6月，艾伦·图灵研究所发布《理解人工智能伦理和安全》指南，这是目前英国公共部门关于人工智能伦理和安全主题的最全面的指南，它识别了人工智能系统可能造成的潜在危害，并提出了具体、可操作的措施。

2016年开始，加拿大政府出台了一系列措施倡导负责任地使用人工智能技术，发布了《2017—2021年信息管理和信息技术战略计划》和《自动化决策指令》，明确使用人工智能的基本指导原则，制定了自动决策指令发展时间表和人工智能供应商“白名单”，构建了“算法影响评估”（AIA）机制等，确定了人工智能技术发展的方向，保障了人工智能技术应用的服务价值、安全性和敏捷性。

澳大利亚近年来一直致力于推动人工智能技术的创新与应用。2019年4月，澳大利亚工业创新和科技部发布了澳大利亚政府资助英联邦科学与工业研究组织CSIRO的Data61起草的《人工智能：澳大利亚的伦理框架》，其提出人工智能研发的8项基本准则，首次规范人工智能的研发道德标准。作为一个自愿性的伦理框架，它倡议AI技术的发展和应用应该为所有澳大利亚人实现更安全、可靠和更公平的结果，应该减少人工智能应用对受影响群体造成负面影响的风险；在设计、开发和应用人工智能时，企业和政府遵守最高的伦理标准。

2.面向大数据伦理监管的重点议题与政策布局

从大数据伦理监管的重点议题来看，全球主要发达国家都不同程度地将监管重点集中于大数据安全与数据隐私保护等方面。

具体来看，美国对大数据伦理监管的政策布局主要集中于数据隐私保护领域。《美国数据隐私和保护法》为公司收集的个人信息制定国家标准和保障措施，包括旨在解决算法潜在歧视影响的保护措施。这代表了美国在制定全面的数据隐私法方面取得的进展，并且成为美国联邦政府开展AI中的大数据监管体系的重要组成部分。针对数据主体实体的差异性，ADPPA确定了几种不同类型的实体，这些实体具有额外的义务或豁免权。对于某些义务，涵盖的实体按“影响”（即年度全球收入和受实体运营影响的数据主体数量）和“与数据主体的关系”（表现为直接关系、第三方关系或服务提供商关系等）进行分类，实现对数据主体和主体关系之间的分类监管。

欧盟域内的国家从20世纪70年代开始就分散制定关于数据隐私保护相关的法规和条例，如《个人数据自动化处理之个人保护公约》（简称《第108号公约》）等。《保护个人享有的与个人数据处理有关的权利以及个人数据自由流动的指令》《一般数据保护条例》分别于1995年和2018年发布，逐渐构建起欧盟域内相对严格的个人数据隐私保护的监管体系。2022年，欧盟相继发布了《数据法案》《数据治理法案》和《数字服务法案》等，这些法案分别针对非个人数据流动和使用、数据共享和再利用、不同类型数字平台服务企业等重要细分领域或主体的数据伦理提出了具体的监管措施，是对《一般数据保护条例》的完善，也是针对新问题或新主体提出的新监管措施。

为了实现英国国家数据战略的愿景，英国数字、文化、媒体和体育部和政府数字服务局（GDS）发布了《数据伦理框架》。2020年9月，英国数字、文化、媒体和体育部发布《国家数据战略》，随后《数据伦理框架》进行了进一步的更新。《数据伦理框架》指导政府和更广泛的公共部门以适当和负责任的方式使用数据。2022年6月17日，英国政府公布了《数据：一个新的方向》，这是一项关于英国数据保护法改革的咨询文件，最初是在2021年9月10日启动的，它提出了各种广泛的改革，囊括了对《通用数据保护条例》（简称GDPR）、《2018年数据保护法》和《隐私和电子通信条例》（简称PECR）等现行主要数据法规详细且全面的修正建议，涉及数据保护管理与问责、数据泄露报告、人工智能规制、国际数据传输、数据访问规则、ICO机构调整等重要领域。

韩国严格保护大数据安全和数据隐私，韩国政府从20世纪90年代后期就开始制定关于数据隐私保护相关的法规和条例等，具有代表性的是个人信息领域的3法，即1995年开始实施的《信用信息的利用及保护法》、2001年开始实施的《信息通信网络利用促进及信息保护法》、2011年开始实施的《个人信息保护法》，并以专门领域立法中个人信息保护相关的法律规范作为必要的补充，逐渐构建起相对严格的个人数据主权和数据隐私保护的监管规则体系。

澳大利亚针对大数据技术应用中的数据隐私保护问题，形成了以1988年《隐私法》为基础、2014年《隐私法》重大改革为核心、各州独立隐私法律分别实施（覆盖地方与州政府机构）、澳大利亚信息专员办公室监督实施的用户数据隐私保护体系。此外，2021年10月25日，澳大利亚总检察长办公室发布了《2021年隐私立法修正案（加强在线隐私和其他措施）法案》，该草案旨在通过引入《在线隐私守则》（OP Code）、扩大1988年《隐私法》的域外管线范围，以及加强对违规行为的处罚来加强对个人信息的保护，重点强化规范大型网络平台、社交媒体、数据经纪商（Data Broker）对个人数据隐私的使用。

3.面向区块链伦理监管的重点议题与政策布局

在区块链技术领域的数字科技伦理监管方面，全球主要发达国家对区块链技术开发与应用的伦理监管重点集中于信息安全与数据隐私安全等方面，但对区块链科技伦理监管的重点议题与政策布局有所差异，其中，美国集中于区块链金融领域，欧盟、韩国与加拿大等侧重于区块链虚拟货币交易过程中的信息安全与隐私保护等。

具体来看，美国主要采取立法的形式进行区块链伦理监管。2021年5月28日，美国众议院能源和商业委员会的立法听证会提出了《区块链创新法案》，其监管目标主要是减少欺诈、提高商业交易的安全性。美国对区块链伦理监管的政策布局主要集中于区块链透明度，特别是注重监管在商业活动中的区块链关键核心技术的跨国转移，美国通过明确的行业特定监管框架，让个人和企业在美国更成功地参与区块链相关的商业活动，包括监管实体和开发商在内的决策者可以使用监管沙盒等工具来提高区块链监管效率。

欧盟区块链伦理监管主要集中在个人信息安全、数据隐私保护、虚拟货币等方面，其伦理监管政策主要集中在大数据伦理监管政策和反洗钱监管政策等。2019年4月，欧盟正式成立国际可信区块链应用协会（INATBA）。2020年1月10日，欧盟发布的《第5次反洗钱和反恐融资指令》（AMLD5）生效。2020年12月3日，《欧盟反洗钱第六号指令》（AMLD6）宣布对成员国生效，且域内金融机构被要求在2021年6月3日之前遵守该指令。以上两项反洗钱指令的生效将从事虚拟货币兑换服务的主体和钱包托管服务商等纳入反洗钱监管，并且明确了其尽职调查的内容和措施，将欧盟的反洗钱和反恐领域的金融融资扩展到了虚拟货币领域。

韩国区块链伦理监管的重点议题与欧盟有类似之处，韩国政府对区块链伦理监管主要集中虚拟货币、个人信息安全和隐私保护等方面。在区块链伦理监管的政策布局方面，2017年12月13日，在国务总理（国务调整室长）主持的企划财政部、法务部、金融委员会、广播通信委员会、公平交易委员会、科学技术信息通讯部次官会议上，政府讨论了虚拟货币投机过热和利用虚拟货币进行犯罪行为等的紧急应对方案。

2014年，加拿大议会成为世界上第一个通过数字货币国家法律的政府，确立了加拿大在全球数字资产领域的领导者地位。自加密行业成立以来，对于监管的需求就出现了两极分化的状态。投资者和企业迫切需要合规的流程，为此必须有一个监管框架。另外，一个监管过度的经济体可能会使加拿大孤立起来，无法融入更广泛的数字资产行业，从而迫使他们进行海外投资。因此，取得二者间的平衡是加拿大构建加密行业支持环境的关键。

四、全球主要发达国家数字科技伦理监管的主导模式及其机制

（一）美国：国会立法主导式监管

与英国、欧盟、韩国等国家或地区相比，美国的数字科技伦理监管更依赖于政府立法主导式的监管模式。实际上，美国在引入立法模式监管数字科技伦理也从犹豫阶段走向了坚定落实阶段，呈现出一个渐进式的监管模式转型。具体而言，在特朗普执政期间，政府机构被劝阻不要引入新的监管措施，因为担心这些措施会阻碍创新。从2021年初开始，可以看到有限治理的稳步出台。《2020年国家人工智能倡议法案》要求建立多个机构来提供联邦级指导，其中，最著名的是国家人工智能计划办公室（NAIO），该办公室全面负责支持人工智能研发、教育计划、跨机构规划和国际合作。联邦政府机构也在推行其他举措，如美国国家标准与技术研究院（NIST）制定的《人工智能风险管理框架》（AI RMF 1.0）。总体来说，美国对数字科技伦理监管的立法特点是强调促进创新以保持美国在数字科技特别是人工智能领域的全球领导地位，重新利用现有法律并引入目前有利于治理的软法，这意味着美国对数字科技伦理监管立法模式的重点依然是在规范数字科技良性生态发展的同时，以硬法+软法相结合的方式推动数字科技竞争力改善。

（二）欧盟：“整体政府”统筹式监管

欧盟作为一个多国家集合体，具有一定程度的特殊性，这决定了成员国在数字经济发展和监管政策领域存在诸多差异。欧盟的总体性政府机构在面向欧盟国家与地区的数字科技伦理监管过程中发挥着重要作用，欧盟在数字科技伦理监管中既制定了全域内的伦理监管政策，也将相应的专业性监管权力赋予了欧盟成员国，实行欧盟整体和成员国两个层面的监管制度体系构建和机构设置，形成欧盟“整体政府”为基础的统筹式监管。在欧盟整体层面，针对数字科技伦理监管陆续颁发了一系列政策，对全域内的数字科技伦理进行监管或指导，如《一般数据保护条例》《可信赖的人工智能伦理准则》等。且在以欧盟为核心的总体性监管中，欧盟侧重于制定统一性的战略部署，包括《人工智能战略》《欧洲数据战略》、“地平线2020”、“地平线欧洲（2021—2027）”、《2023—2024年数字欧洲工作计划》和《2030数字罗盘：欧洲数字十年之路》等，为统一欧盟域内数字经济大市场提供战略指引。同时也存在一定弹性的指令和准则性约束，也有法律层面的硬性约束。在欧盟整体层面的数字科技伦理监管政策要求或指导下，成员国结合自身数字科技发展情况，纷纷制定相应的数字科技伦理监管政策。以大数据伦理监管政策制定为例，《一般数据保护条例》《数据保护执法指令》等在欧盟层面发挥统领和指导作用，并在相关条款中指出允许成员国实施更加具体的监管政策。爱尔兰、德国等成员国根据自身特点修订或制定了大数据伦理监管的相关政策。其中，爱尔兰为与欧盟的《电子隐私指令》中关于cookie等技术的使用、数据缩小和个人数据隐私的监管保持一致性，发布了适用于爱尔兰本土的《电子隐私条例》；对原有的数据保护法律进行修订后形成了《2018年数据保护法》，并设立数据保护委员会。德国在大数据伦理监管领域，2018年发布《德国联邦数据保护法》，该法在遵守《一般数据保护条例》的基础上，根据德国国情对部分条款进行了细化和补充。同样，为了执行欧盟的《电子隐私指令》，德国也相应制定了《电信和电信媒体数据保护法》，其规定了电信和电信媒体在数据保护上的原则，亮点在于设置了隐私保护和用户同意权的相关条款。除了以上两个国家，其他成员国也有相应的监管制度建设。这就构建了欧盟整体层面和成员国层面两个层级的数字科技伦理监管体系，从而保障欧盟数字科技伦理监管政策的有效落地和执行的一致性和协调性。

（三）韩国：泛国家统筹式监管

从韩国数字科技伦理监管的政策布局来看，政府的主导性体现在以韩国科学技术信息通讯部为主管部门并联合其他政府机构将数字科技伦理监管的相关内容渗透到国家战略、产业政策、治理机制和法律框架等构建中，具有一定的权威性和强制性，形成了泛国家统筹式监管模式。

为了刺激数字科技发展，韩国政府和科研机构制定了一系列发展战略和规制。

在韩国政府总体规划与部署方面，2012年，教育科学技术部（现在的科学技术信息通讯部）、行政安全部等韩国政府相关部门联合发表了旨在通过创造性利用数据实现智能强国的“大数据总体规划”；2016年6月9日，泛政府层面根据《信息保护产业振兴相关法律》制定了第一次《信息保护产业振兴计划（2016—2020年）》，并进一步2020年6月发布了泛政府层面作为法定计划的第二次《信息保护产业振兴计划（2021—2025年）》；2018年2月，韩国科学技术审议会（2018年4月并入科学技术咨询会议）审议并通过了《第四次科学技术基本草案》，此次国家科学技术基本计划以2040年未来愿景为目标，设定了2018—2022年韩国的科技发展目标，强调“以人为本”，共设立了4大战略。2019年9月3日科学技术信息通讯部等9个机关联合制定了《国家网络安全基本规划》等。在专门领域的数字科技伦理监管政策部署方面，2018年4月，韩国科学技术院人工智能研究所发布了《人工智能伦理宪章》。在此基础上，韩国科学技术信息通讯部与智能信息社会振兴院联合发布了“智能信息社会伦理指导方针和智能信息社会伦理宪章”；2019年，韩国科学技术信息通讯部进一步发布了《人工智能（AI）国家战略》、2020年发布了《以人为中心的人工智能（AI）伦理标准》《人工智能法律、制度、规制整顿路线图》、2021年发布了《可靠的人工智能实现战略》。不难看出，韩国政府在总体性的规划与宏观战略部署下，进一步结合专业领域特别是人工智能技术领域开展数字科技伦理监管政策部署，无一不体现出韩国对数字科技创新发展和数字化转型的重视和支持，真正将“超越IT强国，成为AI强国”的国家战略融入其中，同时将数字科技伦理监管相关的政策嵌入整个数字科技创新发展过程之中，为数字经济发展提供良好的外部治理环境。

（四）英国：政府部门与跨政府组织联动式监管

在面向数字科技伦理监管过程中，英国政府部门与咨询小组和委员会、网络和社区等跨政府组织上下联动，建立了协作机制，共同对数字科技伦理进行监管和规范，形成政府部门与跨政府组织联动式监管模式。在政府部门层面，英国信息专员办公室、英国数字、文化、媒体和体育部、数据伦理与创新中心（CDEI）、竞争和市场管理局、人工智能办公室（Government Office for AI）、英国金融行为监管局、全国AI研究所、数据标准管理局等政府部门和公共机构都不同程度针对相应监管领域，对人工智能伦理框架、大数据伦理框架、基于区块链的加密货币资产指南、算法伦理与决策偏见审查、数字监管机构合作、包容性数据等领域进行了前瞻性研究，并形成了数字科技伦理监管的初步框架。特别是政府部门针对数字科技伦理采取的是去中心监管方式，2022年，英国发布的《支持创新的人工智能监管方式》中提到，针对数字科技伦理的监管是一种去中心化的监管方法，提出利用现有监管机构的经验和专业知识，通过发布指导意见来强调适用于各个部门的相关伦理监管要求，以应对技术变革，这意味着政府部门主导的数字科技伦理监管更加侧重专业化的力量，采取非集中化的监管方式适应数字科技创新与变革，并将部分监管权力下放给特定行业监管机构和地方议会，同时积极推动国际合作，建立全球范围内的人工智能等数字科技的治理框架，确保数字科技监管能够充分考虑不同地区的不同应用情境，且确保数字科技伦理监管不损害创新的潜力。

考虑到政府主导的去中心化数字科技伦理监管可能难以产生监管协同效应，英国政府制定一套跨部门的数字科技伦理治理原则作为去中心化的数字科技伦理监管体系的补充，表现为政府部门、行业专家和学者等多方成员共同制定数字科技伦理监管政策和建议，并协调各部门的监管行动。咨询小组和委员会、网络和社区等跨政府组织通过在政府部门设立秘书处、向政府部门提供建议、提供开放社区等共同对数字科技伦理进行监管和规范。例如，2020年10月，英格兰银行和英国金融行为监管局成立了人工智能公私论坛（AIPPF），以促进公共部门、私营部门和学术界之间关于人工智能的对话，探索如何支持人工智能在金融领域的安全采用。

（五）日本：多元社会主体分散参与式监管

日本的数字科技伦理监管具有多元主体参与的特点，具体表现在两方面：第一，政府、行业团体、企业和社会力量共同参与监管过程。政府具有管理国家的职能，是监管架构中具有行政权力的组织，但面临数字科技伦理问题，政府没有过分依赖行政强制手段，而是采取了引导的方式，通过民主讨论、凝聚共识、形成合力等寻找解决问题的最佳方案。行业团体如日本经济团体联合会、日本电子信息技术产业协会、日本边缘计算协会、日本云计算联盟等不同社会团队代表企业利益参与数字科技伦理监管。第二，各主体在监管的各个环节发挥不同作用。在规则（包括激励措施）制定阶段，政府牵头、聘请各方人士，采取会议或研究会形式，经过若干次讨论，形成文字文件，由政府发布。参加讨论者以行业团体、企业居多，此外还有哲学、经济学、人工智能学界、法律界、会计界人士和消费者团体等。这个阶段，制定行业、企业的监管规则，也是行业团体、企业的重要职能。行业团体的作用体现在两方面：一是帮助政府实施伦理审查和认证；二是对本行业企业执行伦理规则的情况进行调查和提出建议。企业作为数字科技伦理监管的重要主体，企业除了自我监督、履行说明责任以外，加强内外部监查也是常用的手段。社会力量中尤其是消费者、媒体通过两个途径发挥监督作用：一是参与政府实施的伦理监管调查，二是主导第三方实施的伦理监管调查评估。

五、发达国家对中国建立与完善数字科技伦理监管体系的借鉴

（一）监管制度设计借鉴：重视政府立法的前瞻性引导作用，充分发挥地方政府监管的自主性与积极性

从全球主要发达国家的监管制度设计来看，不同国家或地区都不同程度地将数字科技伦理监管嵌入到特定的发展战略之中，《塑造欧洲数字未来》《2030数字罗盘：欧洲数字十年之路》《欧洲人工智能战略》《欧洲数据战略》等便是监管制度安排内嵌于特定数字科技发展战略的主要例证。在注重软性发展战略引导数字科技伦理监管制度设计的过程中，全球主要发达国家也充分发挥政府前瞻性立法这一关键监管制度安排，确保监管的相关原则、手段和监管法规能够应用到微观企业组织与社会个体，进而在政府监管制度设计层面逐步形成宏观战略牵引与微观主体行为引导双重监管体系。

具体来看，美国作为数字经济与数字科技发展的领头羊，在长期的发展过程中形成了国会为主导的美国政府立法与标准引领的数字科技伦理监管模式，充分发挥国会、白宫政府的重要制度供给，又充分发挥美国州政府的自治原则与自主性原则，形成联邦政府与州政府的双层监管体系。更为关键的是，美国对数字科技伦理监管的总体政策布局依然尊重市场的基本规律，特别是建立在不伤害创新的基本前提下开展数字科技伦理监管，监管的目标考量侧重市场效应和社会福利效应的双重均衡。欧盟发挥统一性的政策与战略指引作用的同时，特别是在数字科技伦理监管的综合性监管政策方面发挥统一部署的重要功能，欧盟域内的成员国需要执行相关的监管条款，并且延伸到域外的国家和企业主体，如《数据治理法案》《人工智能法案》《一般数据保护条例》《网络安全法》等相关监管条款均由欧盟统一制定，相关成员国针对本国实际重点实施。在相关监管法律制度执行层面，欧盟通过建立人工智能伦理委员会，指导并加强与成员国监管机构的合作，促进成员国之间的政策协调，就人工智能伦理监管相关条例实施的相关事项发表意见或建议，并促进成员国人工智能伦理监管部门的经验交流与合作。

基于此，中国在开展数字科技伦理监管制度设计时，一方面，政府需要在全局性发展战略层面覆盖相关伦理监管领域的主要议题，特别是在涉及国民经济与社会发展的相关全局性规划、产业发展战略与规划等文本中体现数字科技伦理监管的相关重点议题，强化国民经济与社会发展中不同主体对数字科技创新发展进程中的基本预期，加强不同市场主体和社会主体对数字科技伦理的认知，确保顶层制度设计层面能够涵盖数字科技伦理监管的重点领域。另一方面，中国需要充分借鉴美国、欧盟等国家或地区基于立法的形式开展数字科技伦理监管，以法律为最高准绳与牵引，并充分发挥市场的调节功能，面向数字科技重点行业与重点领域开展相关立法工作，如针对人工智能技术尽快探索通用性人工智能与专用性人工智能监管法等，确定不同类型人工智能伦理监管的主要主体、主要对象、主要议题和主要措施等。目前中国针对数字科技伦理监管总体上存在立法滞后，目前出台的伦理监管政策包括《关于加强科技伦理治理的意见》《科技伦理审查办法（试行）》（征求意见稿），这些主要是泛化意义上的伦理监管立法，针对数字科技的不同领域的专门性立法尚不多见。《中华人民共和国网络安全法》《中华人民共和国数据安全法》《中华人民共和国个人信息保护法》等法律中已经涉及到网络安全、数据分级分类监管、数据安全流动和个人隐私保护等相关内容，落脚点多在于安全性、有序性、应用和价值释放等，对于数字科技伦理的相关内容较少涉及。此外，政府在监管制度设计与执行过程中需要充分考虑数字科技在不同地区发展的差异性，形成“中央政府—地方政府”相互协同的监管体系，鼓励地方政府在部分重点领域开展监管条例试点探索。在监管制度设计的目标取向方面，其重要目标之一在于识别、控制和防范数字科技开发、应用于创新过程中的道德伦理风险和公共社会风险，以最大程度降低风险源、最大程度控制风险环节为基本原则，开展各类数字科技伦理监管的制度设计。

（二）监管模式设计借鉴：形成政府、企业与社会多元主体共同参与的监管模式

在监管模式设计方面，全球主要发达国家关于数字科技伦理的监管模式主要是政府战略引领、法律牵引和市场自治的方式开展各类数字技术伦理监管与治理，并充分引入社会利益相关方的广泛参与，调动社会组织、标准组织和研究机构在数字科技伦理监管过程中的积极性，这意味着充分发挥政府对数字科技伦理的宏观政策制定与调控作用，更好地发挥市场主体特别是从事数字科技创新、开发与应用主体的自我治理的重要作用，也能够充分发挥社会主体的协同性力量，共同支撑有为政府与有效市场下的监管体制机制顺畅运行。

具体来看，美国数字科技伦理监管在发挥州政府积极性与自主性的基础上，进一步通过国会、联邦政府其他部门的制度建构和政策布局推动整体性的数字科技伦理监管行动。例如，在人脸识别技术的监管方面，美国在联邦政府层面仍未出台统一的规定，而主要依靠州政府充分发挥自主性政策设计原则，由各州政府出台的立法开展自主监管。欧盟“整体政府”框架引领下成员国各具特色的双重监管，且在具体性的监管过程注重社会多元主体的广泛参与，政府在监管政策设计、机构设置和政策推行中发挥主导作用。在相关伦理监管政策制定和机构的设置中，政府部门会广泛征集利益相关方的意见或建议，其中，包括其他相关的政府部门、研究机构和咨询机构、社会组织、企业和公民等主体，这样既可以对政策制定和机构设置提供一定数量和质量的意见，防止监管疏漏，也可以让利益主体具有一定的参与感，充分调动积极性，有助于伦理监管政策的落地。英国政府已经在数字科技伦理监管方面采取了积极行动，将部分监管权力下放至分权行政机构苏格兰政府、威尔士政府和北爱尔兰政府，因而苏格兰政府、威尔士政府和北爱尔兰政府在某些数字科技领域拥有高度的政策自主权。同时，英国政府在数字科技伦理监管方面强调多元利益主体的参与，包括公众、行业专家和学者等，这有助于建立一个更加开放和包容的监管体系，更好地保障公众的利益。

中国在数字科技伦理监管模式设计时，一方面，考虑到中国数字技术创新与应用呈现出区域发展不平衡、行业发展不平衡的现状，中国需要根据地方数字经济发展状况、数字科技重点行业发展状况和面临的风险等级开展精准分类，对不同行业、不同应用场景和不同风险等级的重点行业、重要领域和主要监管对象等开展制度分类设计，有效发挥中央顶层制度设计和地方具体政策执行自主性的优势，确保中央政府与地方政府在面向数字科技伦理监管中的制度框架一致性与政策协同性，确保监管过程合意合效。另一方面，考虑到政府组织、企业组织和社会组织等不同组织在数字科技伦理监管中的功能定位、主要角色和参与机制，中国应充分调动各类监管主体的积极性与能动性，确保监管过程中各类监管主体能够最大程度地参与，实现监管目标协同、监管过程有效和监管效果良好。特别是在面向人工智能伦理监管、大数据伦理监管和区块链伦理监管等重点领域，中国需要进一步提高公众关于立法等相关政策制定的参与度。特别是政府为核心主体在制定特定数字产业或者数字企业监管政策的过程中，在涉及到个人隐私保护、企业正常经营活动和其他经济主体的正当利益的监管过程中，需要纳入社会参与机制与政策制定的信息透明度，提高社会公众参与程度，更好地平衡社会多元利益相关方的价值诉求和正当利益。

（三）监管合作借鉴：形成面向国际社会广泛合作交流的监管机制

从全球主要发达国家的数字科技伦理监管机制来看，主要发达国家不仅仅充分发挥国家范围内的监管主体的重要作用，也充分注重监管的国际动态性和监管机制设计的国际范例。

具体来看，欧盟通过签订贸易合作协议、联合制定监管规则、举办部长级会议和多边论坛等方式来加强国际合作与交流，不断提高欧盟数字科技伦理监管规则的国际认同性。此外，欧盟数字科技伦理监管体系具有一定的“长臂管辖”特征，要求所涉及企业遵守相关的条款，以此来提高欧盟数字科技伦理监管制度的影响力。例如，在数据隐私保护、人工智能可信任性上，欧盟除了要求成员国遵守相应的监管规则之外，还要求数据流入国、特定“守门人”等均要按照相关监管规则来开展经营活动。

借鉴欧盟数字科技伦理合作监管机制构建的经验，中国应该加强与不同国家或地区以及国际组织之间的数字科技伦理监管的合作与交流。在《新一代人工智能发展规划》《“十四五”大数据产业发展规划》《网络安全产业高质量发展三年行动计划（2021—2023年）》等促进数字科技发展的相关文件中，促进国际合作与交流、参与国际规则或标准制定是其中重要的保障措施，对于国际合作与交流具有了一定的认识。未来，中国可以进一步吸收和借鉴欧盟、美国等国家或地区关于数字科技伦理监管的制度建设情况，以补足自身监管的漏洞。特别是中国在构建具有全球引领性的数字科技伦理监管体系过程中，需要着重以国际合作与交流的方式，将中国的数字科技伦理监管的相关理念或制度推广至其他国家或地区，加强与不同国家或地区之间数字科技伦理监管制度的互认互通，提高影响力与认可度。最后，中国应主动参与联合国教科文组织等国际组织全球性数字科技伦理监管政策的制定过程，推动中国数字科技伦理监管原则、监管尺度和监管政策与全球数字科技伦理监管体系对接相容。

 

参考文献

[1]李正风,王硕.数字素养、数据权利与数字伦理[J].科普研究,2022,17(6):8-14,108.

[2]阳镇，陈劲.数智化时代下的算法治理——基于企业社会责任治理的重新审视[J].经济社会体制比较，2021(2):12-21.

[3]黎常,金杨华.科技伦理视角下的人工智能研究[J].科研管理,2021,42(8):9-16.

[4]贾开.人工智能与算法治理研究[J].中国行政管理,2019,403(1):17-22.

[5]薛孚,陈红兵.大数据隐私伦理问题探究[J].自然辩证法研究,2015,31(2):44-48.

[6]邱仁宗,黄雯,翟晓梅.大数据技术的伦理问题[J].科学与社会,2014,4(1):36-48.

[7]TANG Y,XIONG J,BECERRIL-ARREOLA R,et al.Ethics of blockchain:a framework of technology,applications,impacts,and research directions[J].Information Technology&People,2019,33（2）：602-632.

[8]肖红军，阳镇，商慧辰.平台监管的多重困境与范式转型[J].中国人民大学学报，2022(4):24-39.

[9]肖红军，阳镇.平台企业社会责任：逻辑起点与实践范式[J].经济管理，2020(4):37-53.

[10]阳镇，陈劲.数智化时代下企业社会责任的创新与治理[J].上海财经大学学报，2020(6):33-51.

[11]肖红军,阳镇.数字科技伦理监管：美国进展与中国借鉴[J].财经问题研究,2023,(6):73-86.

[12]LENK H.,MARING M.Advances and problems in the philosophy of technology[M].Munster:LIT,2001:5-10.

[13]朱海林.技术伦理、利益伦理与责任伦理——工程伦理的三个基本维度[J].科学技术哲学研究,2010,27(6):61-64.

 

肖红军,阳镇.数字科技伦理监管的理论框架、国际比较与中国应对[J/OL].东北财经大学学报:1-16[2023-08-16].http://kns.cnki.net/kcms/detail/21.1414.f.20230807.1126.002.html.
